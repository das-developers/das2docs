#!/usr/bin/env python3

from os.path import basename as bname
import argparse
import sys

from lxml import etree
try:
    from StringIO import StringIO # Python 2
except ImportError:
    from io import StringIO       # Python 3
	 
g_sSchema = 'das2.3-basic.xsd'

# ########################################################################### #
class PacketReader:
	def __init__(self, fIn):
		self.fIn = fIn
		self.lPktSize = [None]*100
		self.lPktDef  = [False]*100
		self.nOffset = 0

	def setDataSize(self, nPktId, nBytes):
		if nPktId < 1 or nPktId > 99:
			raise ValueError("Packet ID %d is invalid"%nPktid)
		if nBytes <= 0:
			raise ValueError("Data packet size %d is invalid"%nBytes)
		
		self.lPktSize[nPktId] = nBytes
		
	def __iter__(self):
		return self
	
	def __next__(self):
		x4 = self.fIn.read(4)
		if len(x4) != 4:
			raise StopIteration
			
		try:
			nPktId = int(x4[1:3].decode('utf-8'), 10)
		except ValueError:
			raise ValueError("Invalid packet ID '%s'"%x4[1:3].decode('utf-8'))
			
		
		if (nPktId < 0) or (nPktId > 99):
			raise ValueError("Invalid packte ID %s at byte offset %s"%(
				x4[1:3].decode('utf-8'), self.nOffset
			))
			
		self.nOffset += 4			
		
		if self.nOffset == 4 and (x4 != b'[00]'):
			raise ValueError("Input does not start with '[00]' does not appear to be a das2 stream")
		
		if x4[0:1] == b'[' and x4[3:4] == b']':
			# In a header packet, save data as utf-8 (it already is)
			
			x6 = self.fIn.read(6)	
			if len(x6) != 6:
				raise ValueError("Pre-mature end of packet %s"%x4.decode('utf-8'))
				
			self.nOffset += 6
			
			nLen = 0
			try:
				nLen = int(x6.decode('utf-8'), 10)
			except ValueError:
				raise ValueError("Invalid header length %s for packet %s"%(
					x6.decode('utf-8'), x4.decode('utf-8')
				))
				
			if nLen < 8:
				raise ValueError(
					"Packet length (%d) is to short to be a legal for packet %s"%(
					nLen, x4.decode('utf-8')
				))
			
		
			xDoc = self.fIn.read(nLen)
			self.nOffset += nLen
			sDoc = None
			try:
				sDoc = xDoc.decode("utf-8")
			except UnicodeDecodeError:
				ValueError("Header %s (length %d bytes) is not valid UTF-8 text"(
					x4.decode('utf-8'), nLen
				))
			
			self.lPktDef[nPktId] = True
			
			# Higher level parser will have to give us the length.  This is an
			# oversight in the das2 stream format that has been around for a while.
			# self.lPktSize = ? 
			
			return ('header', nPktId, sDoc)
		
		elif (x4[0:1] == b':') and  (x4[3:4] == b':'):
			# The old das2.2 packets which had no length, you dad to parse the
			# header.
			
			if not self.lPktDef[nPktId]:
				raise ValueError(
					"Undefined data packet %s encountered at affset %d"%(
					x4.decode('utf-8'), self.nOffset
				))
			
			if self.lPktSize[nPktId] == None:
				raise RuntimeError(
					"Internal error, unknown length for data packet %d"%nPktId
				)
			
			xData = self.fIn.read(self.lPktSize[nPktId])
			self.nOffset += len(xData)
			
			if len(xData) != self.lPktSize[nPktId]:
				raise ValueError("Premature end of packet data for id %d"%nPktId)
			
			return ('data', nPktId, xData)

		elif (x4[0:1] == b'|') and (x4[3:4] == b'|'):
			# In a possibly variable length packet, read it
			x7 = self.fIn.read(7)	
			if len(x7) != 7:
				raise ValueError("Pre-mature end of packet %s"%x4.decode('utf-8'))
			
			self.nOffset += 7
			
			nLen = 0
			try:
				nLen = int(x7[0:6].decode('utf-8'), 10)
			except ValueError:
				raise ValueError("Invalid data length %s for packet %s"%(
					x6.decode('utf-8'), x4.decode('utf-8')
				))
				
			if nLen < 8:
				raise ValueError(
					"Packet length (%d) is to short to be a legal for packet %s"%(
					nLen, x4.decode('utf-8')
				))
			
			xData = self.fIn.read(nLen)
			self.nOffset += len(xData)
			
			if len(xData) != nLen:
				raise ValueError("Premature end of packet data for id %d"%nPktId)
			
			return ('data', nPktId, xData)
		
		else:
			raise ValueError(
				"Expected the start of a header or data packet at offset %d"%self.nOffset
			)
			
# ########################################################################### #
def getValSz(sType):
	"""das2 type names always end in the size, just count backwards and 
	pull off the digits.  You have to get at least one digit
	"""
	sSz = ""
	for c in reversed(sType):
		if c.isdigit(): sSz += c
		else: break
	
	sSz = ''.join(reversed(sSz))
	return int(sSz, 10)

# ########################################################################### #
def getDatLen(packet, nPktId):
	"""Given a <packet> element, recurse through top children and figure 
	out the data length"""
	
	nSize = 0
	for child in packet:
	
		if child.tag not in ('x','y','z','w','yset','zset','wset'):
			continue
					
		nItems = 1
		if child.tag in ('yset','zset','wset'):
			if 'nitems' in child.attrib:
				nItems = int(child.attrib['nitems'], 10)
								
		# Add sizes for all the planes, they all have the same number of items
		# but mak have different value sizes
		for subChild in child:
			if subChild.tag == 'plane':
			
				# Get the value type
				if 'type' not in subChild.attrib:
					raise ValueError(
						"Attribute 'type' missing for element %s in packet ID %d"%(
						subChild.tag, nPktId
					))
			
				nSzEa = getValSz(subChild.attrib['type'])
				nSize += nSzEa * nItems
			
	return nSize
			

# ########################################################################### #
def main(lArgs):

	# Ignore confusing help formatting for now.  (I think newline character
	# insertion in help output is the most requested feature of argparse.)
	
	psr = argparse.ArgumentParser(
		description="das2.3-basic stream validator"
	)
	
	psr.add_argument(
		'-s','--schema', default=g_sSchema, help="XSD schema file to load, "+\
		"defaults to %s."%g_sSchema + " Use this option to select the "+\
		"strict schema if desired.", dest='sSchema', metavar='XSD'
	)
	
	psr.add_argument(
		'-p', '--prn-hdrs', default=False, action="store_true",
		help="Print each das2 header encountered in the stream prior to "+\
		"schema validation.", dest='bPrnHdr'
	)
	
	# End command line with list of files to validate
	psr.add_argument(
		'lFiles', help='The file(s) to validate', nargs='+', metavar='FILE'
	)
	
	args = psr.parse_args()

	print("Reading XSD: %s"%args.sSchema)
	fSchema = open(args.sSchema)
	schema_doc = etree.parse(fSchema)
	schema = etree.XMLSchema(schema_doc)
	
	if len(args.lFiles) == 0:
		print("No input files specified, so... all done right?")
		return 0
	
	for sFile in args.lFiles:
	
		print("Validating: %s"%sFile)
		fIn = open(sFile, 'rb')
	
		lDatPkts = [0]*100
	
		reader = PacketReader(fIn)
	
		for (sType, nPktId, xPkt) in reader:
		
			if sType == 'data':
				lDatPkts[nPktId] += 1
				continue
		
			if args.bPrnHdr:
				print(xPkt)
			fPkt = StringIO(xPkt)
		
			try:
				doc = etree.parse(fPkt)
			except etree.XMLSyntaxError as e:
				print(xPkt)
				print("ID: %s <%s> [FAILED]"%(nPktId, sType))
				print(str(e))
				return 5
		
			sType = doc.getroot().tag
		
			# Make sure it validates		
			try:
				schema.assertValid(doc)
			except etree.DocumentInvalid as e:
				print("ID: %s <%s> [FAILED]"%(nPktId, sType))
				print(str(e))
				return 5		
			
			# If this is a packet element, get the total length
			if sType == 'packet':
				nDatLen = getDatLen(doc.getroot(), nPktId)
				reader.setDataSize(nPktId, nDatLen)
				#print("For Packet ID %s, data size is %d"%(nPktId, nDatLen))
				print("ID: %s <%s> [OKAY] (data size %d bytes)"%(nPktId, sType, nDatLen))
			else:
				print("ID: %s <%s> [OKAY]"%(nPktId, sType))
			
		for nPktId in range(100):
			if lDatPkts[nPktId] != 0:
				print("ID: %d has %d data packets [OKAY]"%(nPktId, lDatPkts[nPktId]))
		
		print('File "%s" validates'%sFile)
	
	if len(args.lFiles) == 1:
		print("against schema %s"%bname(args.sSchema))
	else:
		print("All %d stream files validated against %s"%(
			len(args.lFiles), bname(args.sSchema))
		)
		
	return 0	

# ########################################################################### #
if __name__ == "__main__":
	sys.exit(main(sys.argv))
